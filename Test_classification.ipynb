{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from options.test_options import TestOptions, Opt_test\n",
    "from data import DataLoader\n",
    "from models import create_model\n",
    "from util.writer import Writer\n",
    "from test import run_test\n",
    "from util.mesh_viewer import *\n",
    "from util.util import print_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mean / std from cache\n",
      "#test meshes = 120\n",
      "loading the model from ./checkpoints\\shrec16\\latest_net.pth\n"
     ]
    }
   ],
   "source": [
    "opt = Opt_test()\n",
    "opt.parse()\n",
    "# These options must match the options for training!\n",
    "opt.dataroot = 'datasets/shrec_16' \n",
    "opt.name = 'shrec16'\n",
    "opt.ncf = [64, 128, 256, 256] \n",
    "opt.pool_res = [600, 450, 300, 180]\n",
    "opt.norm = 'group'\n",
    "opt.resblocks = 1 \n",
    "opt.export_folder = 'stuff'\n",
    "\n",
    "\n",
    "dataset = DataLoader(opt)\n",
    "dataset_size = len(dataset)\n",
    "print('#test meshes = %d' % dataset_size)\n",
    "model = create_model(opt)\n",
    "writer = Writer(opt)\n",
    "\n",
    "def test_all(opt, dataset, model, writer, epoch=-1):\n",
    "    print('Running Test')\n",
    "    #opt = TestOptions().parse()\n",
    "    opt.serial_batches = True  # no shuffle\n",
    "    #dataset = DataLoader(opt)\n",
    "    #model = create_model(opt)\n",
    "    \n",
    "    # test\n",
    "    writer.reset_counter()\n",
    "    for i, data in enumerate(dataset):\n",
    "        model.set_input(data)\n",
    "        ncorrect, nexamples = model.test()\n",
    "        writer.update_counter(ncorrect, nexamples)\n",
    "    writer.print_acc(epoch, writer.acc)\n",
    "    return writer.acc\n",
    "\n",
    "def test_random(opt, dataset, model):\n",
    "    num_obj = np.random.randint(len(dataset))\n",
    "    opt.serial_batches = True \n",
    "    for i, data in enumerate(dataset):\n",
    "            if i == num_obj//16:\n",
    "                idx = num_obj - num_obj//16*16\n",
    "                model.set_input(data)\n",
    "                out = model.forward()\n",
    "                pred_class = out.data.max(1)[1]\n",
    "                #ncorrect, nexamples = model.test()\n",
    "                print('Correct class: %s' % dataset.dataset.classes[data['label'][idx]])\n",
    "                print('Predicted class: %s' % dataset.dataset.classes[pred_class[idx]])\n",
    "        \n",
    "                obj_name = dataset.dataset.paths[num_obj][0]\n",
    "                print('see object file %s for visualization' % obj_name.split('\\\\')[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test\n",
      "epoch: -1, TEST ACC: [98.333 %]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_all(opt, dataset, model, writer, epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: armadillo\n",
      "Predicted class: armadillo\n",
      "see object file T473.obj for visualization\n"
     ]
    }
   ],
   "source": [
    "test_random(opt, dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset.classes\n",
    "ting = dataset.dataset.paths[0][0]\n",
    "view_meshes(ting, dataset.dataset.paths[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Network initialized -------------\n",
      "[Network] Total number of parameters : 1.323 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_network(model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeshConvNet(\n",
       "  (conv0): MResConv(\n",
       "    (conv0): MeshConv(\n",
       "      (conv): Conv2d(5, 64, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): MeshConv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "  (pool0): MeshPool()\n",
       "  (conv1): MResConv(\n",
       "    (conv0): MeshConv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): MeshConv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm1): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "  (pool1): MeshPool()\n",
       "  (conv2): MResConv(\n",
       "    (conv0): MeshConv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): MeshConv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "  (pool2): MeshPool()\n",
       "  (conv3): MResConv(\n",
       "    (conv0): MeshConv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): MeshConv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 5), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm3): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "  (pool3): MeshPool()\n",
       "  (gp): AvgPool1d(kernel_size=(180,), stride=(180,), padding=(0,))\n",
       "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
